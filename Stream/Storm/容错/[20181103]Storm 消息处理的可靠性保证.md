---
layout: post
author: sjf0115
title: Storm 消息处理的可靠性保证
date: 2018-11-03 21:33:01
tags:
  - Storm

categories: Storm
permalink: guaranteeing-message-processing-in-storm
---

Storm 提供了几种不同级别的保证消息处理语义，包括 Best Effort，At Least Once，以及通过 Trident 的 Exactly Once。这篇文章中描述了 Storm 如何保证 At Least Once 处理语义。

### 1. 消息完整处理

一个元组从 Spout 发送出来，可能会创建基于它产生的数千个元组。下面我们看一个流式 `单词统计` 的拓扑：
```java
TopologyBuilder builder = new TopologyBuilder();
builder.setSpout("sentences", new KestrelSpout("kestrel.backtype.com", 22133, "sentence_queue", new StringScheme()));
builder.setBolt("split", new SplitSentence(), 10)
        .shuffleGrouping("sentences");
builder.setBolt("count", new WordCount(), 20)
        .fieldsGrouping("split", new Fields("word"));
```
这个拓扑从 Kestrel 队列中读取一个完整的英文句子，然后将这个句子分解成独立的单词，最后发送每个单词以及它出现过的次数。每个从 Spout 发出的元组都会触发创建许多基于它的元组：句子中每个单词的元组和每个单词更新计数的元组。这些元组构成一个树状结构，我们称之为"元组树"。一个元组树看起来像这样：
![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/guaranteeing-message-processing-in-storm-1.png?raw=true)

> Kestrel 为 scala 实现的消息队列组件，具体参考[kestrel](https://github.com/twitter-archive/kestrel)

当元组树不再生长，并且元组树中的每一个元组都已经被处理，则认为这个从 Spout 发出的元组被完整处理。如果在指定的超时时间内，一个元组衍生出来的元组树未被完全处理完，则认为这个元组未被完整处理。可以通过 `Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS` 参数为指定拓扑设置消息处理超时时间，默认为30秒。

### 2. 消息生命周期

如果消息被完整处理或未完整处理，后面会发生什么，让我们来先看看从 Spout 发出来的元组的生命周期。下面时一个 Spout 实现接口：
```java
public interface ISpout extends Serializable {
    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);
    void close();
    void nextTuple();
    void ack(Object msgId);
    void fail(Object msgId);
}
```
首先，Storm 通过调用 Spout 上的 `nextTuple` 方法从 Spout 请求一个元组。Spout 使用 `open` 方法中提供的 `SpoutOutputCollector` 向输出流中发送一个或者多个元组（可以向多个输出流发送元组）。每发送一个元组，Spout 都会提供一个 `消息ID`，后面用来标识这个元组。例如，KestrelSpout 从 kestrel 队列中读取消息，Spout 会将 Kestrel 队列为这个消息设置的 id 作为这个消息的 `消息ID`。向 `SpoutOutputCollector` 发送消息如下所示：
```java
_collector.emit(new Values("field1", "field2", 3) , msgId);
```
接下来，元组被发送到消费的 Bolt 上，并且 Storm 会负责跟踪创建的消息树（追踪由此消息产生的新消息）。当 Storm 检测到元组已经被完整处理，Storm 就会调用 Spout 任务上的 ack 方法，并将消息ID作为参数传入。同样，如果元组超时 Storm 就会在 Spout 上调用 fail 方法。一个元组被 ack 还是 fail 都是由原来创建该元组的 Spout 任务来完成的。因此，如果 Spout 在集群上执行多个任务，是不会通过与创建它的任务不同的任务来确认 ack 或 fail。

让我们再次使用 KestrelSpout 来看看 Spout 需要做些什么来保证消息处理可靠。当 KestrelSpout 从 Kestrel 队列中取出一条消息时，它会`打开`该消息。这意味着消息实际上并未从队列中取出，而是处于`挂起`状态，等待消息确认。处于挂起状态时，消息不会向队列的其他使用者发送。此外，如果客户端断开连接了，则该客户端的所有的挂起消息会被重新放回队列。当一条消息被打开，Kestrel 提供给客户端消息数据和一个唯一的消息ID，KestrelSpout 用这个ID作为 Storm 发送元组时的`消息ID`。后续某时刻，当 KestrelSpout 的 ack 或 fail 方法被调用时，KestrelSpout 会通过 Kestrel 客户端确认消息已经被消费或是重新放回消息队列。

### 3. Storm的可靠性API

如果想利用 Storm 的可靠性，需要我们做两件事：
- 只要在元组树中创建新链接，就需要告诉 Storm。
- 当你处理完单个元组时，你需要告诉 Storm。
通过执行这两项操作，Storm 可以检测元组树何时完全处理完，并对 Spout 元组调用 ack 或 fail。Storm 的API提供了完成这两项任务的简洁方法。

在元组树中指定链接称之为锚定。锚定是在发送新元组的同时完成的。我们以下面的 Bolt 为例。此 Bolt 将包含句子的元组拆分为每个单词的元组：
```java
public class SplitSentence extends BaseRichBolt {
    OutputCollector _collector;

    public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
        _collector = collector;
    }

    public void execute(Tuple tuple) {
        String sentence = tuple.getString(0);
        for(String word: sentence.split(" ")) {
            _collector.emit(tuple, new Values(word));
        }
        _collector.ack(tuple);
    }

    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word"));
    }        
}
```
通过将输入元组指定为 emit 方法的第一个参数来锚定每个单词元组。由于单词元组被锚定，如果单词元组在下游处理中失败，则稍后将重放树跟节点的 Spout 元组。作为相比，让我们看一下如果像这样发出单词元组会发生什么：
```java
_collector.emit(new Values(word));
```
以这种方式发出单词元组会使其无法被锚定。如果在下游处理中处理失败，则不会重放根节点元组。有时发出未锚定的元组也是可以的，这需要根据拓扑中所需的容错语义来决定。

输出元组可以锚定到多个输入元组。这在进行流连接或聚合时很有用。多锚定元组处理失败时将导致从 Spout 重放多个元组。通过指定元组列表而不仅仅是单个元组来完成多锚定。例如：
```java
List<Tuple> anchors = new ArrayList<Tuple>();
anchors.add(tuple1);
anchors.add(tuple2);
_collector.emit(anchors, new Values(1, 2, 3));
```
多锚定将输出元组添加到多个元组树中。请注意，多锚定也可以打破树结构，创建元组DAG，如下所示：
![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/guaranteeing-message-processing-in-storm-2.png?raw=true)

锚定是指定元组树的方式 -  Storm 的可靠性API的下一部分是指定何时完成处理元组树中的单个元组。这是通过在 OutputCollector 上使用 ack 和 fail 方法完成的。你可以回看一下 SplitSentence 示例，你可以看到在发送所有单词元组之后输入元组被 ack。

你可以调用 OutputCollector 上的 fail 方法对元组树根处的 Spout 元组快速失败。例如，你的应用程序可能会选择从数据库客户端捕获异常并显式地使输入元组失败。通过显示地使元组失败，可以比等待元组超时更快地重放 Spout 元组。

你处理的每个元组都必须被 ack 或 fail。Storm 使用内存来跟踪每个元组，因此如果你不对每个元组进行 ack 或者 fail，那么这个任务最终会耗尽内存。

许多 Bolt 遵循读取输入元组的共同模式，基于它发送元组，然后在 execute 方法结束时 ack 元组。这些 Bolt 属于过滤器类别和简单功能。Storm 有一个名为 BasicBolt 的接口，它为你封装了这种模式。SplitSentence 示例可以使用 BasicBolt 编写，如下所示：
```java
public class SplitSentence extends BaseBasicBolt {
    public void execute(Tuple tuple, BasicOutputCollector collector) {
        String sentence = tuple.getString(0);
        for(String word: sentence.split(" ")) {
            collector.emit(new Values(word));
        }
    }

    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word"));
    }        
}
```
这个实现比之前的实现更简单，并且在语义上是相同的。发送到 BasicOutputCollector 的元组会自动锚定到输入元组，并在 execute 方法完成时自动为你对输入元组 ack。

相反，执行聚合或连接的 Bolt 可能会延迟对元组进行 ack，直到它根据一堆元组计算出结果为止。聚合和连接通常也会对它们的输出元组进行多锚定。这些东西已经不属于 IBasicBolt 的简单模式。

### 4. 重放元组时如何使应用程序正常工作

如果你真的想使用 Exactly Once 语义，请使用 Trident API。在某些情况下，例如大规模的数据分析，丢失数据是正常的，因此通过 `Config.TOPOLOGY_ACKERS` 参数将 acker bolt 的数量设置为 0 来禁用容错。但在某些情况下，我们希望确保所有内容都至少处理过一次，并且不能删除任何内容。如果所有操作都是幂等的，或者重复删除有可能发生，则这个功能比较有用。

### 5. 实现可靠性

Storm 拓扑具有一组特殊的 acker 任务，用于跟踪每个 spout 元组的元组 DAG。当 acker 知道 DAG 完成时，它会向创建该 Spout 元组的那个 Spout 任务发送一条信息来对这个元组进行 ack。你可以使用 `Config.TOPOLOGY_ACKERS` 对指定拓扑设置拓扑的 acker 任务数。`Config.TOPOLOGY_ACKERS` 默认为每个 Worker 一个任务。

了解 Storm 可靠性实现的最佳方法是查看元组和元组DAG的生命周期。当在拓扑中创建元组时，无论是在 Spout 还是 Bolt 中，都会给它一个随机的64位id。Ackers 使用这些 id 来跟踪每个 Spout 元组的元组 DAG。

每个元组都知道所有 Spout 元组的ID，因为它们存在元组树中。当你在一个 Bolt 中发送一个新的元组时，来自元组的锚点的 Spout 元组 id 会被复制到新的元组中。当一个元组被 ack 时，它会向相应的 acker 任务发送一条消息，包含元组树如何变化的信息。特别是它告诉 acker "我在元组树中已经完成对这个 Spout 元组的处理，树中一些新的元组锚定在我身上"。

例如，如果元组 D 和 E 是基于元组 C 创建的，下面显示了当 C 被 ack 时元组树如何变化：
![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/guaranteeing-message-processing-in-storm-3.png?raw=true)

因为从树中移除 C 的同时，又添加了 D 和 E，因此树永远不会提前完成。

还有一些关于 Storm 跟踪元组树的细节。如前所述，你可以在拓扑中设置任意数量的 acker 任务。这会导致如下问题：当拓扑中的元组被 ack 时，如何知道发送信息到哪个 acker 任务？Storm 是使用取模哈希算法去映射一个 Spout 元组 id 到某个 acker 任务的。因为每个元组都带有它们已经存在所有树上的 Spout 元组 ids，所以它们知道应该跟哪个 acker 任务去通信。

Storm 的另一个细节是 acker 任务如何跟踪哪个 Spout 任务对他们正在跟踪的每个 Spout 元组负责。当 Spout 任务发送新元组时，它只是简单的向相应的 acker 发送一条消息，告诉它这个任务 id 负责该 Spout 元组。然后，当 acker 看到元组树已经完成时，它知道发送完成消息到哪个任务ID。

Acker 任务不会显式跟踪元组树。对于具有数万个节点（或更多）的大型元组树，跟踪所有元组树可能会压垮 ackers 使用的内存。相反，如果 ackers 采用不同的策略，每个 Spout 元组只需要恒定大小的空间（大约20个字节）。这种跟踪算法是 Storm 工作的关键，也是其重大突破之一。

Acker 任务存储为一个 Map，Spout 元组 id 为 key，一对值为 value。第一个值是创建 Spout 元组的任务ID，后面会用于发送完成消息。第二个值是64位数字，称为 `ack val`。`ack val` 表示整个元组树的状态，无论多大。它只是在树中创建或确认的所有元组ID的异或值。

当 acker 任务看到 `ack val` 变为 0 时，就知道元组树已经完成。由于元组 id 是随机的64位数，因此 `ack val` 意外变为 0 的可能性非常小。如果你以每秒 10K 的速度进行数学计算，则需要花费5000万年才出现错误。即使这样，如果拓扑中的元组发生故障，它也只是会导致数据丢失。

既然你已经了解了可靠性算法，那么让我们回顾一下所有的失败案例，看看 Storm 在每种情况下如何避免数据丢失：
- Task挂掉，元组不会被 ack：在这种情况下，失败元组在树根处的 Spout 元组id会超时并进行重放。
- Acker Task 挂掉：在这种情况下，该 acker 跟踪的所有 Spout 元组都将会超时并重放。
- Spout Task 挂掉：在这种情况下，Spout 任务获取数据的数据源负责重放消息。例如，当客户端断开连接时，像 Kestrel 和 RabbitMQ 这样的队列会将所有挂起的消息放回队列中。

如你所见，Storm 的可靠性机制是完全分布式，可伸缩和容错的。

### 6. 可靠性优化

Acker 任务是轻量级的，因此在一个拓扑中不需要很多该任务。你可以通过 Storm UI（组件ID`__acker`）来跟踪它们的性能。如果吞吐量看起来不正确，则需要添加更多的 acker 任务。

如果可靠性对你不重要 - 也就是说，你不关心在失败情况下丢失元组 - 那么你可以通过不跟踪 Spout 元组的元组树来提高性能。不跟踪元组树会将传输的消息数减半，因为正常情况下在元组树中的每个元组都有一条确认消息。此外，在每个下游元组中保留更少的ID，从而减少带宽使用。有三种方法可以消除可靠性：
- 第一种是将 `Config.TOPOLOGY_ACKERS` 设置为 0。在这种情况下，Storm 会在 Spout 发送元组后立即调用 Spout 上的 ack 方法，不会跟踪元组树。
- 第二种方法是基于消息消除可靠性。你可以通过在 `SpoutOutputCollector.emit` 方法中省略消息ID来关闭单个 Spout 元组的跟踪。
- 最后，如果你不关心拓扑中下游元组的特定子集是否无法处理，你可以将它们作为未锚定的元组发出。因为它们没有锚定到任何 Spout 元组，所以如果它们没有被 ack，它们不会导致任何 Spout 元组失败。

> Storm 版本: 2.0.0-SNAPSHOT

原文：[Guaranteeing Message Processing](http://storm.apache.org/releases/2.0.0-SNAPSHOT/Guaranteeing-message-processing.html)
