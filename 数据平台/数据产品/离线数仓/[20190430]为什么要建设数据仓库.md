

### 1. 数据需求响应慢

老板把你叫过去，问：昨天成交额是多少，答：我回去查一下，半小时后告诉你。老板的心顿时凉了半截。这半个小时，对于你是多么地紧迫，对于老板也是度日如年。半小时后，你告诉他：数字是xxx亿。老板接着问：xx类目成家额是多少。答：半小时后....

我们的现实情况可能比这还更糟，有些数据说不清，理还乱，一周都不一定能把数据算出来。

数据仓库是面向决策的，面向分析的。数据仓库需要能快速的响应数据需求。如何解决这一问题呢？

80%的数据需求是相对固定的，20%的需求是比较随意的。相对固定的需求主要是业务的监控数据，例如: 某天UV多少,PV多少，收入多少。。。。，这些需求的指标是固定的，变化的只是维度组合，以及数据的粒度层次。举个例子，以店铺经业务为例，运营人员关心的指标无非是UV，PV，订购人数，订购金额，但是他们会从多个维度去看，如时间维度，店铺星级，店铺类型，主营类目。数据粒度指的是在某一维度上，要看到那个层次，以类目为例，是看一级类目呢还是叶子类目，以地域为例，是看省分布呢还是到市级。我们可以将业务方常用的维度组合以及粒度层次开发成固定的报表，开发支持裁剪和钻取的OLAP报表，提供灵活的维度和粒度组合查询分析。

另外20%的数据需求，需要case by case开发统计，费时费力。经过长期的总结会发现，这部分需求有如下的特点。首先是数据计算口径较特别，例如月销售额大于2000的卖家人数。其次，跨业务，例如统计订购了小艾分析的量子用户的销售额区间分布，包含了第三方产品订购业务、量子业务，又包含淘宝主站业务。其次，依赖细粒度数据。需求的随意性，导致必须从细粒度的数据中统计数据，需要考虑的口径多，计算时间长。为了满足这类需求，最好能提供一个快速自助查询细粒度数据的平台，将个性化的操作交给最终用户，解放数据仓库工程师的人力。

上述内容，主要从数据展现产品的角度，将需求拆分为金字塔结构，分层次地提供多种数据产品，满足数据需求。要实现上述目标，还需要搭建层次清晰数据仓库模型，将数据分为细粒度、初步汇总、高度汇总的金字塔结构的数据层，分别覆盖100%，90%，80%的数据需求。要求数据仓库模型指标定义规范统一、层次分明、业务主题清晰、高度解耦。

### 2. 数据质量不可靠

#### 2.1 数据不一致

经常接到运营人员的旺旺消息：
```
亲，今天UV怎么暴涨这么多？什么原因？
亲，店铺经里的XX指标与淘数据的不一致，那个靠谱？什么原因？
```

第一种情况，数据出现异常波动，属于数据指标自身纵向不一致。造成此问题的原因多为ETL程序健壮性不够，由于数据源发生变化，ETL程序不能兼容次变化，导致结果数据异常波动。例如，acookie日志中增加了新的log，ETL程序未作过滤；直通车PV日志出现重复，导致广告效果数据翻倍等等。

防止此类问题发生的办法，一是要做好上下游变更通知机制，让下游能预知上游的变更，以便做好准备和处理。另一方面，ETL程序要有一定的兼容性，尽可能避免一些异常数据导致结果数据错误。

从数据仓库建模角度，通过分层能有效控制这类问题的发生。在ODS层统一处理LOG的变化和异常；或者在DW层中，设一个适配层，专门适配上游的各种变化。

第二种情况，属于数据统计口径问题。不同的数据团队，或统一团队的不同人员，对同一个业务指标的理解不一致，各自在统计的时候做了特殊的过滤或者其他处理，导致数据结果不一致。还有一种可能就是开发人员为了满足某个特定需求，做个特别的处理，而下游引用此数据的成员不知情，导致数据不一致的产生。

解决这一问题，首先要有全局意识。个人生产的数据不是仅仅为自己服务，不仅仅是为某个需求服务。而要把数据看做公司的，集体的资产，开发人员要对本数据正确性负责，也要对下游能简单明了地理解本数据负责。要做好团队间和团队内部的工作协同，能互通有无，有变化有情况能即时周知。

另一方面就是工作的标准化、专业化。除了上层应用可以有个性化，可以有锦上添花，数据仓库中下层一定要是标准化的，规范化的，应该有统一的规划和设计，不要因人而异。还要加强数据仓库建模技术的培训，让新人能掌握建模技术和规范，也要让团队成员达成一致，采用相同的建模技术和方法。具体到仓库模型，ODS和FACT层不要面向具体数据需求，不要做特别的处理。如果有特别口径的指标怎么办？那就新建一个指标。

有很多的数据仓库工具，用于辅助标准化、专业化。元数据管理非常重要。元数据一方面描述数据仓库的系统信息。更重要的的方面是描述数据本身，描述数据仓库包含什么数据，数据如何组织，数据在什么地方；还有每个指标的统计口径，数据口径的描述功在当代，利在千秋，一定不要偷懒。举个简单的例子，我们几百个表里涉及到成交金额，但是都没有描述金额单位是元还是分，每次开发的时候都需要去询问责任人，后者一层一层翻代码，真的很累，很低效，而且还有看错的风险。。。。



2、数据不可信



    老板拿着一份报表问：这个数据靠谱吗？我要拿去和客户讲....

    两种回答，A：没问题。...... B：我回去核实一下......

    如果是你，你能否做出坚定的回答呢？



       这个例子和数据可靠性有什么关系呢？每次听到这个问题，都是对数据仓库的一次检验，也是对数据仓库工程师的一次考验。

       要做出坚定的回答不容易。一方面，要对业务要有认识，要经常看数据，保持对数据的敏感。例如：你看到某天淘宝成交额是100亿，根据你的业务认识，结合近期的数据，你肯定能做出一个肯定的回答。如果有人告诉你京东某天成交额是10亿，你很难做出肯定回答。

       另一方面，良好的数据仓库设计，能让你对数据质量充满信心。面对数据正确性的质疑，尽管90%的case，数据都是正确的，但总得花很多时间去验证正确性。所以数据便于追溯验证非常必要。

      为了便于验证数据，数据流不能太复杂，每个指标都有统一的数据来源，而不是N个近似来源；数据流层次要清晰，从ODS到RPT层，最好不要超过5层，云梯上很多表，依赖层次都是20层以上，这是有非常大的风险的。如果数据流程清晰，因此数据验证效率高代价低，会带来一系列的良性循环。如果有别要的话可以开发一套数据指标监控和验证的程序，来做系统性的保障。



       总之，数据质量问题归根结底是数据仓库治理的问题。从管理上要做好协同、规范、标准；从数据仓库设计上要层次分明、数据流程简洁；同时要用数据仓库的元数据管理、数据质量监控验证系统等组件来辅助解决问题

。。。
