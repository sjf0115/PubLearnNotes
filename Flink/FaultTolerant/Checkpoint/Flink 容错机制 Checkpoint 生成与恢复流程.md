Flink 是一个分布式数据处理系统，因此必须有一套机制处理各种故障，例如进程被强制杀掉、机器故障和网络连接中断。任务都是在本地维护状态，所以 Flink 要确保状态不丢以及不错。

在本节中，我们将介绍 Flink 的检查点是如何恢复和生成的，看它们是如何保证精确一次 Exactly-Once 语义的状态一致性。

## 1. 一致性检查点

Flink 的故障恢复机制的核心需要基于应用状态的一致检查点。有状态流应用的一致性检查点是在所有任务处理完等量的原始输入后对全部任务状态进行的一个拷贝，注意这里需要处理等量原始输入。一致性检查点过程可以通过一个简单算法步骤来解释：
- 暂停输入：暂停接收所有输入流，即不再接收新数据的输入
- 处理已输入数据：等待已经流入系统的数据被完全处理，即所有任务已经处理完所有的输入数据。这时候每个任务都会处理等量的原始输入。
- 状态拷贝：将所有任务的状态拷贝到远程持久存储，生成检查点。在所有任务完成自的拷贝工作后，检查点生成完毕  
- 恢复输入：恢复所有数据流的接收

需要注意的是 Flink 实现的并不是这种简单的机制，而是一种更加复杂的检查点算法。下图展示了一个简单应用中的一致性检查点：

![](1)

上面的应用程序中具有一个 Source 任务，负责从一个递增的数字(1、2、3、4...)流中东读取数据。数字流会被划分为偶数流和奇数流。SUM 算子的两个任务(sum_even 和 sum_odd)会分别计算当前所有偶数和奇数的总和。Source 任务会将其输入流的当前偏移量存储为状态，而求和任务则将当前的总和值存储为状态。在上图所示，Flink 会在输入偏移量为 5 时，将检查点写入了远程存储，当前的总和为 6 和 9。

## 2. 从一致性检查点中恢复

在执行流应用程序期间，Flink 会周期性的为应用状态生成一致性检查点。一旦发生故障，Flink 会利用最新的检查点将应用状态恢复到某一个一致性的点并重启处理进程。图下图展示了整个恢复过程：

![](2)

应用程序状态从检查点恢复分为三个步骤：
- 重新启动整个应用程序。
- 利用最新的检查点重置任务状态，即将所有有状态任务的状态重置为最新一次检查点的状态。
- 恢复所有任务的处理。

如果所有算子都将它们全部的状态写入检查点并从中恢复，并且所有输入流的消费位置都能重置到检查点生成那一刻，那么检查点和恢复机制就能为整个应用的状态提供精确一次的一致性保障。

至于数据源是否可以重置它的输入流，需要取决于其实现方式以及所消费的外部系统是否提供相关的接口。例如，像 Apache Kafka 这样的事件日志系统就可以允许从之前的某个偏移量位置读取数据。这种数据源就可以重置到检查点生成那一刻的偏移量，重新消费数据。相反如果数据是从套接字 Socket 消费而来就无法重置，因为套接字的数据一旦被消费就会被丢弃。因此，只有当所有的输入流都是来自于可重置的数据源时，应用才支持精确一次的状态一致性保障。

应用从检查点恢复以后，它的内部状态会和生成检查点那一刻的状态完全一致。随后应用就会重新消费数据并重新处理从检查点生成到系统发生故障之间的所有数据。虽然这意味着 Flink 会重复处理部分消息，但仍然可以实现 Exactly-Once 语义的一致性状态，因为所有算子的状态都会重置到过去还没处理过那些数据的时间点。

需要注意的是，检查点和恢复机制仅能重置流式应用内部的状态。根据应用所采用的 Sink 算子，在恢复期间，某些结果记录会向下游系统发送多次。对于某些存储系统，Flink 提供的 Sink 算子具有精确一次输出，例如可以在检查点完成时才会把写出的记录正式提到。另一种适用于许多存储系统的方法是幂等更新。

## 3. 生成一致性检查点

Flink 的故障恢复机制需要基于应用的一致性检查点。前面我们已经了解了从流式应用中创建检查点的简单方法就是先暂停执行，生成检查点，然后再恢复应用程序。这种方法很好理解，但这种'停止一切'的思路，即使是对于有中等延迟要求的应用程序而言也是不切实际的。所以 Flink 没有这么简单粗暴，而是基于 Chandy-Lamport 分布式快照算法来实现的。该算法不会暂停应用，而是会把生成检查点的过程和处理过程分离，这样就可以实现部分任务持久化状态，而其他任务继续执行而不受影响。接下来我们将解释此算法的工作原理。

Flink 的检查点算法用到了一种称为检查点 Barrier 的特殊记录。与 Watermark 类似，都通过 Source 算子注入到常规的数据流中。相对其他记录，它们的位置是固定好的，在流中的位置不能不能提前也不能延后。为了标识检查点，每个 Barrier 都会带一个检查点编号，把一条数据流分成了两部分。位于 Barrier 之前数据记录的状态会包含在 Barrier 对应的检查点中，而位于 Barrier 之后数据记录的状态会包含在下一个检查点中。

我们通过一个简单的流应用程序示例来一步一步解释这个算法。应用包含了两个数据源 Source 任务，每个任务都会各自消费一条自增数字流。Source 任务的输出会被划分为奇数流和偶数流两部分。每一部分都会有一个任务负责将收到的全部数字求和，并将结果值更新至下游 Sink 任务。具体如下所示：

![](3)

如下图所示 JobManager 会向每个 Source 任务发送一个新的检查点编号，以此启动检查点生成流程：

![](4)

当一个 Source 任务收到消息时，它会暂停发出新的数据记录，利用状态后端触发生成本地状态的检查点，并把该检查点 Barrier 连同检查点编号广播至所有传出的数据流分区中。状态后端会在状态存为检查点完成后会通知任务，虽然任务会向 JobManager 发送确认消息确认完成。在将所有的 Barrier 发出后，Source 任务就可以恢复正常工作。通过向输出流中注入 Barrier，Source 函数定义了需要在数据流中哪些位置生成检查点。如下图展示了流式应用为 Source 任务的本地状态生成检查点并发出 Barrier：

![](5)



....
