当业务标签越来越多时，[宽表标签计算的方案](https://smartsi.blog.csdn.net/article/details/140087260)将不再适合，因为当列越多时，更新效率将会越慢。一种优化方案是通过对标签表构建索引，将用户ID编码后以 Bitmap 格式保存(一般使用 [RoaringBitmap](https://smartsi.blog.csdn.net/article/details/127833352) 进行压缩存储)，将关系运算转化 Bitmap 的交并差运算，进而加速实时计算性能。如果用户 ID 是字符类型，需要先将用户ID进行整数编码才能使用 Bitmap 存储。


在一些业务场景中，我们需要将字符串映射为一个整形数字，并确保全局唯一，比如在BitMap字典索引计算场景。常用的方法是将数据集根据需要映射的字符串做全局order by排序，将排序号作为字符串的整形映射。该方式能达到目标，但如果一次要计算的数据量太大（十亿级别或更大），会跑耗时较久甚至跑不出来。﻿

本文提供一种能充分利用分布式计算资源来计算全局字典索引的方法，以解决在大数据量下使用上诉方式导致所有数据被分发到单个reducer进行单机排序带来的性能瓶颈。

## 1. ROW_NUMBER 方案

在 [用户画像实战：基于 ROW_NUMBER 的全局字典设计与实现](https://smartsi.blog.csdn.net/article/details/140508529) 一文中介绍了如何使用 ROW_NUMBER 构建全局字典从而将用户ID进行整数编码。


user_df 是全量用户表，表中 uid 由不同字符组成的字符串且唯一，数据量级在亿级别，直接对数据表全局开窗排序写法如下：
```sql
INSERT OVERWRITE TABLE user_dict
SELECT uid, ROW_NUMBER() OVER (ORDER BY uid ASC ) AS idx
FROM user_df;
```
这种方式耗时30分钟，reducer只有一个，在这种方式下reducer只能有一个才能保证是全局唯一的。

## 2. 分布式优化思路

大数据量下计算最忌讳的就是演变为单机计算，好一点的情况是跑很久，数据量再大可能直接跑不出来。如何利用计算资源水平扩展的优势来解决？思路是先做分桶进行分布式局部排序、再基于桶大小得到全局索引。类似于操作系统指令寻址的基址寻址，我们需要对每个id做绝对地址映射，利用一个基址加上相对地址得到绝对地址。


第一步先对 uid 做 hash 分桶，然后计算每个桶的大小，桶数量可以根据需要计算的 uid 数量来评估，这里分 100000 个桶，然后计算出每个 uid 在桶内的相对位置 bucket_slot_index，同时计算出桶大小 bucket_size：
```sql
WITH hash_bucket AS (
    SELECT
        uid
        -- 计算桶内的相对位置，即槽位索引
        ,ROW_NUMBER() OVER (PARTITION BY bucket_index ORDER BY uid ASC ) AS bucket_slot_index
        -- 桶大小
        ,COUNT(1) OVER (PARTITION BY bucket_index ) AS bucket_size
        -- 桶位置索引
        ,bucket_index
    FROM (
      SELECT uid, ABS(HASH(id)) % 100000 AS bucket_index
      FROM user_df
    )
)
```
第二步根据桶大小计算每个桶的基址：
```sql
WITH bucket_base AS (
    SELECT  
        bucket_index
        ,SUM(bucket_size) OVER (ORDER BY bucket_index ASC ) - bucket_size AS bucket_base
    FROM (
        SELECT bucket_index, bucket_size
        FROM hash_bucket
        GROUP BY bucket_index, bucket_size
    )
)
```
第三步将桶基址+id在桶内的相对地址得到全局唯一的绝对地址id_index；
```sql
SELECT  
    /*+ MAPJOIN(a2) */
    a1.id
    ,a2.bucket_base + bucket_slot_index AS user_index
FROM hash_bucket a1
JOIN bucket_base a2
ON a1.bucket_index = a2.bucket_index;
```
