

### 1. Example

下图中，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果`K=3`(表示只看最近三个元素)，由于在最近三个元素中红色三角形所占比例为2/3(大于蓝色四方形所占比例1/3)，所以绿色圆将被赋予红色三角形那个类，如果`K=5`，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。

### 2. 思想

K最近邻(k-Nearest Neighbor，`KNN`)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN方法虽然从原理上也依赖于极限定理，但在类别决策时，只与极少量的相邻样本有关。由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于`类域的交叉或重叠较多的待分样本集`来说，KNN方法较其他方法更为适合。

KNN算法不仅可以用于分类，还可以用于回归。通过找出一个样本的k个最近邻居，将这些邻居的属性的平均值赋给该样本，就可以得到该样本的属性。更有用的方法是将不同距离的邻居对该样本产生的影响给予不同的权值(weight)，如权值与距离成反比。
